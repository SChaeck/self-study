{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyarrow\n",
    "# !pip install fastparquet\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 저장\n",
    "df = pd.read_parquet(\"data/train-00000-of-00001.parquet\")\n",
    "\n",
    "X_train = df['sentence']\n",
    "Y_train = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 저장\n",
    "df = pd.read_parquet(\"data/validation-00000-of-00001.parquet\")\n",
    "\n",
    "X_test = df['sentence']\n",
    "Y_test = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 토큰화 \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# 단어 개수 저장\n",
    "word_to_index = tokenizer.word_index\n",
    "vocab_size = len(word_to_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어를 정수로 인코딩\n",
    "X_train_encoded = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# 가장 긴 문장에 길이를 맞추기 위한 패딩 진행\n",
    "max_len = max(len(sample) for sample in X_train_encoded)\n",
    "X_train_padded = pad_sequences(X_train_encoded, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1053/1053 [==============================] - 34s 30ms/step - loss: 0.3430 - acc: 0.8459\n",
      "Epoch 2/2\n",
      "1053/1053 [==============================] - 32s 30ms/step - loss: 0.1799 - acc: 0.9316\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU, LSTM, Bidirectional, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# 임베딩 벡터: 64차원 / 은닉 상태: 64\n",
    "embedding_dim = 64\n",
    "hidden_units = 64\n",
    "\n",
    "# 모델은 임베딩 / Bi-LSTM / Sigmoid로 구성 \n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim)) # 임베딩 레이어\n",
    "model.add(Bidirectional(LSTM(hidden_units))) # Bi-LSTM 레이어\n",
    "model.add(Dense(1, activation='sigmoid')) # 시그모이드\n",
    "\n",
    "# 옵티마이저: adam / 손실함수: BCE\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train_padded, Y_train, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터도 인코딩, 패딩 진행\n",
    "X_test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_encoded, maxlen=max_len)\n",
    "predictions = model.predict(X_test_padded)\n",
    "\n",
    "# 결과값이 0부터 1 사이의 실수이므로 반올림해 0 혹은 1로 변경\n",
    "predictions = np.round(predictions).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8371559633027523\n",
      "정밀도: 0.8431818181818181\n",
      "재현율: 0.8355855855855856\n",
      "F1 점수: 0.8393665158371041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "precision = precision_score(Y_test, predictions)\n",
    "recall = recall_score(Y_test, predictions)\n",
    "f1 = f1_score(Y_test, predictions)\n",
    "\n",
    "print(f'정확도: {accuracy}\\n정밀도: {precision}\\n재현율: {recall}\\nF1 점수: {f1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
